{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Gemini API Integration\n",
    "\n",
    "## Going Straight to the Source\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sanjaynegi309/agentic-ai-course/blob/main/notebooks/07-Gemini-API-Integration.ipynb)\n",
    "\n",
    "Frameworks like LangChain and CrewAI are fantastic for productivity. But to truly master agentic AI, it's essential to understand how to interact with the core models directly. In this chapter, we'll peel back the layers of abstraction and work directly with the **Google Gemini API** to unlock its most powerful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Why Go Native?\n",
    "\n",
    "Using a model's native API offers several advantages:\n",
    "\n",
    "- **Direct Access:** Get immediate access to the latest features, models, and updates without waiting for a framework to support them.\n",
    "- **Maximum Performance:** Reduce potential latency by removing framework overhead.\n",
    "- **Simplicity:** For straightforward tasks, a direct API call is often simpler and requires less code than building a full chain.\n",
    "- **Advanced Features:** Directly control powerful features like streaming, function calling, and multimodal inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and Setup\n",
    "!pip install google-generativeai python-dotenv Pillow requests\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv():\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "    except ImportError:\n",
    "        print(\"Could not load API keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Your First Gemini API Call\n",
    "\n",
    "Let's start with the most basic operation: generating text from a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Basic Text Generation\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "\n",
    "# Choose the model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Generate content\n",
    "response = model.generate_content(\"Explain the concept of an AI agent in one sentence.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Real-Time Responses with Streaming\n",
    "\n",
    "Waiting for the full response can make your application feel slow. With streaming, you can receive the response token-by-token, creating a much more interactive and real-time experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Streaming Content\n",
    "response_stream = model.generate_content(\n",
    "    \"Write a short story about a robot who discovers music.\", \n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(\"--- Streaming Story ---\")\n",
    "for chunk in response_stream:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Multimodality - The 'Vision' in 'Pro Vision'\n",
    "\n",
    "This is where Gemini truly shines. We can send both images and text in a single prompt to the `gemini-pro-vision` model. Let's give it an image and ask a question about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Multimodal Input (Text and Image)\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Fetch an image from a URL\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Tour_Eiffel_Wikimedia_Commons.jpg/800px-Tour_Eiffel_Wikimedia_Commons.jpg\"\n",
    "response = requests.get(image_url)\n",
    "img = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Choose the vision model\n",
    "vision_model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "# Create the multimodal prompt\n",
    "prompt_parts = [\n",
    "    \"What is this famous landmark and in what city is it located?\",\n",
    "    img\n",
    "]\n",
    "\n",
    "# Generate content\n",
    "vision_response = vision_model.generate_content(prompt_parts)\n",
    "\n",
    "print(vision_response.text)\n",
    "display(img) # Display the image in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… When to Use the Native API vs. a Framework\n",
    "\n",
    "| Scenario | Recommendation | Why? |\n",
    "|---|---|---|\n",
    "| Building a complex, multi-step agent with several tools. | **Framework (LangChain/LangGraph)** | Frameworks excel at managing state, orchestrating components, and abstracting complexity. |\n",
    "| Need the absolute latest model feature (e.g., a new API parameter). | **Native API** | Frameworks may lag behind in implementing the newest, most niche features. |\n",
    "| Creating a simple chatbot that requires fast, streaming responses. | **Native API** | A direct streaming call is lightweight and highly performant. |\n",
    "| Prototyping a new agent idea quickly. | **Framework (CrewAI/LangChain)** | High-level abstractions get you up and running faster. |\n",
    "\n",
    "In the next chapter, we'll explore a forward-looking concept for agent-to-agent communication: the **Model Context Protocol (MCP)**. We'll learn what it is and even build a simple local server to see it in action."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
