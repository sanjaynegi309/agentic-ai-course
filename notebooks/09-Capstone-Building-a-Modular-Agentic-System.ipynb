{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Capstone Project - A Modular Agentic System\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sanjaynegi309/agentic-ai-course/blob/main/notebooks/09-Capstone-Building-a-Modular-Agentic-System.ipynb)\n",
    "\n",
    "Congratulations! You've reached the final chapter and the capstone project. It's time to combine everything you've learned‚ÄîLangChain, CrewAI, LangGraph, Hugging Face, and the Gemini API‚Äîinto a single, powerful, and modular agentic system. Let's build something impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ The Mission: A Content Creation & Promotion Pipeline\n",
    "\n",
    "Our goal is to build an automated system that can:\n",
    "1.  Take a topic.\n",
    "2.  Use a **CrewAI** team to research the topic and write a blog post.\n",
    "3.  Use a **native Gemini API** call for a quick review of the post.\n",
    "4.  If the post needs revisions, loop back to the CrewAI team with feedback (**LangGraph** will manage this loop).\n",
    "5.  Once approved, use a specialized **Hugging Face** model to generate a promotional tweet for the blog post.\n",
    "\n",
    "This project demonstrates the power of using the right tool for the right job, orchestrated by a master workflow manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Our Toolkit\n",
    "\n",
    "| Framework/API | Role in Our System |\n",
    "|---|---|\n",
    "| **LangGraph** | The **Master Orchestrator**. It will define the overall workflow, manage the state, and handle the conditional logic (the review loop). |\n",
    "| **CrewAI** | The **Specialist Team**. It will handle the self-contained, multi-step task of researching and writing the initial draft. We'll use it as a 'black box' node in our graph. |\n",
    "| **Hugging Face**| The **Niche Specialist**. We'll use a smaller, specialized model for the specific task of generating a short tweet. |\n",
    "| **Gemini API** | The **Quick Consultant**. We'll use a direct API call for the review step, as it's a simple, single-shot task that doesn't require a full agent setup. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: The Grand Setup\n",
    "!pip install langgraph crewai langchain langchain_google_genai huggingface_hub transformers python-dotenv duckduckgo-search torch\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv():\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "        os.environ['HUGGINGFACE_API_KEY'] = userdata.get('HUGGINGFACE_API_KEY')\n",
    "    except ImportError:\n",
    "        print(\"Could not load API keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Building the CrewAI Node\n",
    "\n",
    "First, we'll create our research and writing crew. The key here is to wrap the entire CrewAI process in a single function that we can use as a node in LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "def create_crewai_node(topic, feedback=None):\n",
    "    \"\"\"Creates and runs the CrewAI research and writing crew.\"\"\"\n",
    "    search_tool = DuckDuckGoSearchRun()\n",
    "    \n",
    "    researcher = Agent(\n",
    "        role='Expert AI Researcher',\n",
    "        goal=f'Find the most relevant and up-to-date information on {topic}.',\n",
    "        backstory='You are a meticulous researcher, skilled at finding facts and synthesizing them.',\n",
    "        tools=[search_tool],\n",
    "        allow_delegation=False\n",
    "    )\n",
    "    \n",
    "    writer = Agent(\n",
    "        role='Professional Tech Blogger',\n",
    "        goal=f'Write an engaging and informative blog post on {topic}.',\n",
    "        backstory='You are a skilled writer, able to turn complex topics into clear, compelling narratives.',\n",
    "        allow_delegation=False\n",
    "    )\n",
    "    \n",
    "    research_task = Task(\n",
    "        description=f'Research the topic: {topic}.',\n",
    "        expected_output='A detailed summary of key points, trends, and examples.',\n",
    "        agent=researcher\n",
    "    )\n",
    "    \n",
    "    writing_description = f'Write a blog post on {topic}.'\n",
    "    if feedback:\n",
    "        writing_description += f' Please incorporate the following feedback: {feedback}'\n",
    "        \n",
    "    writing_task = Task(\n",
    "        description=writing_description,\n",
    "        expected_output='A well-structured, 4-paragraph blog post.',\n",
    "        agent=writer\n",
    "    )\n",
    "    \n",
    "    crew = Crew(agents=[researcher, writer], tasks=[research_task, writing_task], process=Process.sequential)\n",
    "    return crew.kickoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: The Hugging Face & Gemini Nodes\n",
    "\n",
    "Next, we'll create functions for our other specialists: the reviewer (using the native Gemini API) and the social media manager (using a Hugging Face model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "# Gemini node for reviewing\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "reviewer_llm = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def reviewer_node_func(blog_post):\n",
    "    prompt = f\"Review the following blog post. If it is high quality and ready to publish, respond with 'APPROVED'. Otherwise, provide concise feedback for improvement.\\n\\n{blog_post}\"\n",
    "    response = reviewer_llm.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# Hugging Face node for tweeting\n",
    "tweet_generator_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"distilgpt2\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\"max_new_tokens\": 280, \"pad_token_id\": 50256},\n",
    ")\n",
    "\n",
    "def tweet_generator_node_func(blog_post):\n",
    "    prompt = f\"Create a short, punchy tweet to promote this blog post: {blog_post[:500]}\"\n",
    "    response = tweet_generator_llm.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: The LangGraph Orchestrator\n",
    "\n",
    "Now, let's wire everything together using LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Define the state\n",
    "class CapstoneState(TypedDict):\n",
    "    topic: str\n",
    "    blog_post: str\n",
    "    review_feedback: str\n",
    "    tweet: str\n",
    "\n",
    "# Define the graph nodes\n",
    "def content_creation_node(state):\n",
    "    print(\"--- Node: Content Creation Crew ---\")\n",
    "    post = create_crewai_node(state['topic'], state.get('review_feedback'))\n",
    "    return {\"blog_post\": post, \"review_feedback\": None} # Clear feedback after revision\n",
    "\n",
    "def review_node(state):\n",
    "    print(\"--- Node: Reviewer ---\")\n",
    "    feedback = reviewer_node_func(state['blog_post'])\n",
    "    return {\"review_feedback\": feedback}\n",
    "\n",
    "def social_media_node(state):\n",
    "    print(\"--- Node: Social Media Specialist ---\")\n",
    "    tweet = tweet_generator_node_func(state['blog_post'])\n",
    "    return {\"tweet\": tweet}\n",
    "\n",
    "# Define the conditional edge\n",
    "def review_decision(state):\n",
    "    if \"APPROVED\" in state['review_feedback']:\n",
    "        print(\"--- Decision: Approved ---\")\n",
    "        return \"social_media\"\n",
    "    else:\n",
    "        print(\"--- Decision: Revision Needed ---\")\n",
    "        return \"content_creation\"\n",
    "\n",
    "# Assemble the graph\n",
    "graph = StateGraph(CapstoneState)\n",
    "graph.add_node(\"content_creation\", content_creation_node)\n",
    "graph.add_node(\"review\", review_node)\n",
    "graph.add_node(\"social_media\", social_media_node)\n",
    "\n",
    "graph.set_entry_point(\"content_creation\")\n",
    "graph.add_edge(\"content_creation\", \"review\")\n",
    "graph.add_conditional_edges(\"review\", review_decision, {\"social_media\": \"social_media\", \"content_creation\": \"content_creation\"})\n",
    "graph.add_edge(\"social_media\", END)\n",
    "\n",
    "runnable_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run the Pipeline!\n",
    "inputs = {\"topic\": \"The impact of generative AI on creative industries\"}\n",
    "final_state = runnable_graph.invoke(inputs)\n",
    "\n",
    "print(\"\\n\\n--- FINAL OUTPUT ---\")\n",
    "print(\"\\n**Generated Blog Post:**\")\n",
    "print(final_state['blog_post'])\n",
    "print(\"\\n**Generated Tweet:**\")\n",
    "print(final_state['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Course Conclusion\n",
    "\n",
    "Congratulations on building a truly sophisticated, multi-framework agentic system! You have successfully orchestrated a team of specialized agents, managed a complex workflow with loops, and integrated both proprietary and open-source models.\n",
    "\n",
    "You are no longer just a user of AI; you are an architect of intelligent systems. You have the skills to design and build modular, powerful, and efficient AI agents for a vast range of applications.\n",
    "\n",
    "The journey doesn't end here. The field of agentic AI is one of the most exciting and rapidly evolving areas of technology. Continue to experiment, build your own projects, and share your work with the community.\n",
    "\n",
    "**Thank you for taking this course. Now go build the future!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
