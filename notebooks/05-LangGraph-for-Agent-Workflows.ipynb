{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: LangGraph for Complex Agent Workflows\n",
    "\n",
    "## The Director's Chair for Your AI Crew\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPOSITORY/blob/main/notebooks/05-LangGraph-for-Agent-Workflows.ipynb)\n",
    "\n",
    "You've built single agents and linear crews. But what happens when the process isn't a straight line? What if you need loops, branches, and more complex logic? Welcome to **LangGraph**, the library that gives you the power to direct your agents with precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Beyond Linearity: Why We Need Graphs\n",
    "\n",
    "Real-world workflows are rarely linear. Consider a content creation process:\n",
    "\n",
    "1.  A writer creates a draft.\n",
    "2.  An editor reviews it.\n",
    "3.  **If** there are issues, it goes back to the writer for revision (a **loop**).\n",
    "4.  **Otherwise**, it gets published (a **branch**).\n",
    "\n",
    "LangGraph allows us to model these complex, cyclical, and conditional workflows, which are essential for building robust and intelligent agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß± The Building Blocks of LangGraph\n",
    "\n",
    "LangGraph has three core components:\n",
    "\n",
    "1.  **State:** A central Python object (often a `TypedDict`) that is passed between all the nodes in the graph. It's the shared memory of the workflow, and each node can update it.\n",
    "2.  **Nodes:** The 'workers' of the graph. Each node is a Python function that receives the current state, performs an action, and returns a dictionary to update the state.\n",
    "3.  **Edges:** The 'connectors' that define the flow. An edge connects one node to another. **Conditional edges** are special edges that route the flow to different nodes based on the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and Setup\n",
    "!pip install langgraph langchain langchain_google_genai python-dotenv duckduckgo-search\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv():\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "    except ImportError:\n",
    "        print(\"Could not load API keys.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Hands-On: A Research Team with a Review Cycle\n",
    "\n",
    "Let's build a research team that includes a review and revision loop. This is a classic use case for LangGraph.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Researcher:** Finds information on a topic.\n",
    "2.  **Writer:** Writes a draft based on the research.\n",
    "3.  **Reviewer:** Checks the draft. \n",
    "    - If it's good, the process ends.\n",
    "    - If it needs work, it goes back to the writer with feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the State\n",
    "from typing import TypedDict, List\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    research_summary: str\n",
    "    draft_article: str\n",
    "    review_comments: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Nodes\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "def researcher_node(state: ResearchState):\n",
    "    print(\"--- Node: Researcher ---\")\n",
    "    summary = search_tool.run(f\"Summarize the latest news on {state['topic']}\")\n",
    "    return {\"research_summary\": summary}\n",
    "\n",
    "def writer_node(state: ResearchState):\n",
    "    print(\"--- Node: Writer ---\")\n",
    "    prompt = f\"Based on this summary: {state['research_summary']}, write a short blog post.\"\n",
    "    if state.get('review_comments'):\n",
    "        prompt += f\"\\nIncorporate this feedback: {state['review_comments']}\"\n",
    "    \n",
    "    draft = llm.invoke(prompt).content\n",
    "    return {\"draft_article\": draft}\n",
    "\n",
    "def reviewer_node(state: ResearchState):\n",
    "    print(\"--- Node: Reviewer ---\")\n",
    "    prompt = f\"Review this draft: {state['draft_article']}. Is it ready to publish? If not, provide feedback.\"\n",
    "    review = llm.invoke(prompt).content\n",
    "    if \"ready\" in review.lower():\n",
    "        return {\"review_comments\": None}\n",
    "    else:\n",
    "        return {\"review_comments\": review}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define the Graph and Edges\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(ResearchState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"researcher\", researcher_node)\n",
    "graph.add_node(\"writer\", writer_node)\n",
    "graph.add_node(\"reviewer\", reviewer_node)\n",
    "\n",
    "# Define edges\n",
    "graph.set_entry_point(\"researcher\")\n",
    "graph.add_edge(\"researcher\", \"writer\")\n",
    "graph.add_edge(\"writer\", \"reviewer\")\n",
    "\n",
    "# Define the conditional edge\n",
    "def should_continue(state: ResearchState):\n",
    "    if state.get('review_comments'):\n",
    "        return \"writer\" # Loop back to the writer\n",
    "    else:\n",
    "        return END # End the process\n",
    "\n",
    "graph.add_conditional_edges(\"reviewer\", should_continue, {\"writer\": \"writer\", END: END})\n",
    "\n",
    "# Compile the graph\n",
    "runnable_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run the Graph\n",
    "inputs = {\"topic\": \"The future of AI in medicine\"}\n",
    "final_state = runnable_graph.invoke(inputs)\n",
    "\n",
    "print(\"\\n--- Final Result ---\")\n",
    "print(final_state['draft_article'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Visualizing Your Workflow\n",
    "\n",
    "One of the best features of LangGraph is that you can visualize your graph to understand and debug it. This helps ensure your logic is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(runnable_graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This can fail in some environments, so we'll just print the ASCII version\n",
    "    print(runnable_graph.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ LangGraph vs. CrewAI: When to Use Which\n",
    "\n",
    "| Framework | Best For | Key Feature |\n",
    "|---|---|---|\n",
    "| **CrewAI** | Rapidly building role-based agent teams. | High-level, intuitive API for defining agents and tasks. |\n",
    "| **LangGraph**| Building complex, custom workflows with loops and branches. | Fine-grained control over state and flow. |\n",
    "\n",
    "They are not mutually exclusive! You can even use CrewAI agents as nodes within a LangGraph workflow for the best of both worlds.\n",
    "\n",
    "In the next chapter, we'll dive into the vast ecosystem of **Hugging Face**, learning how to integrate pre-trained models and datasets into our agentic systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
