{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: LangChain Fundamentals\n",
    "\n",
    "## The Engine Room of Agentic AI\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOUR_USERNAME/YOUR_REPOSITORY/blob/main/notebooks/03-LangChain-Fundamentals.ipynb)\n",
    "\n",
    "Welcome to the engine room! LangChain is arguably the most popular and comprehensive framework for building applications with Large Language Models. In this chapter, we'll dissect its fundamental components: Chains, Tools, Agents, and Memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⛓️ The Core Idea: Chains (using LCEL)\n",
    "\n",
    "The heart of LangChain is the **chain**. A chain allows you to combine different components (like LLMs, prompts, and tools) in a sequence. The modern way to build chains is with the **LangChain Expression Language (LCEL)**, which uses the pipe operator `|` to connect components.\n",
    "\n",
    "Think of it as a production line: an input goes in one end, passes through several stations, and a final output comes out the other end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and Setup\n",
    "!pip install langchain langchain_google_genai python-dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "if not load_dotenv():\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        os.environ['GEMINI_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
    "    except ImportError:\n",
    "        print(\"Could not load API keys.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build a simple LCEL Chain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Prompt Template\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "\n",
    "# 2. LLM\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
    "\n",
    "# 3. Output Parser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 4. Create the chain using LCEL\n",
    "joke_chain = prompt | llm | output_parser\n",
    "\n",
    "# 5. Run the chain\n",
    "topic = \"ice cream\"\n",
    "print(f\"Joke about {topic}:\\n\")\n",
    "print(joke_chain.invoke({\"topic\": topic}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Giving Your Chain Superpowers: Tools\n",
    "\n",
    "What if your LLM needs to know something it wasn't trained on, like today's date or the result of a complex calculation? That's where **Tools** come in. A tool is a function that an agent or chain can use to interact with the outside world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a custom tool\n",
    "from langchain.tools import tool\n",
    "import datetime\n",
    "\n",
    "@tool\n",
    "def get_current_date(text: str) -> str:\n",
    "    \"\"\"Returns the current date, useful for any questions about today's date.\"\"\"\n",
    "    return str(datetime.date.today())\n",
    "\n",
    "# Let's test the tool\n",
    "print(get_current_date.name)\n",
    "print(get_current_date.description)\n",
    "print(get_current_date.run(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 The Brain of the Operation: Agents Revisited\n",
    "\n",
    "An **Agent** is a special type of chain that has an LLM at its core which can decide which, if any, tools to use. It uses a framework like **ReAct (Reasoning and Acting)** to loop through a cycle of Thought -> Action -> Observation until it has an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create an Agent with our custom tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "tools = [get_current_date]\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm, # Our LLM from before\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "agent.run(\"What date is it today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Don't Forget! Adding Memory\n",
    "\n",
    "By default, chains and agents are stateless. They treat each new query as a completely separate event. To have a real conversation, we need to add **Memory**. Memory allows a chain or agent to remember previous interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Add Memory to a Chain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create a ConversationChain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Start the conversation\n",
    "print(\"--- First Interaction ---\")\n",
    "conversation.predict(input=\"Hi, my name is Jules.\")\n",
    "\n",
    "print(\"\\n--- Second Interaction ---\")\n",
    "conversation.predict(input=\"What is my name?\")\n",
    "\n",
    "# You can inspect the memory\n",
    "print(\"\\n--- Memory Contents ---\")\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Putting It All Together\n",
    "\n",
    "You've now learned about the four pillars of LangChain:\n",
    "\n",
    "1.  **Chains (LCEL):** For composing sequences of operations.\n",
    "2.  **Tools:** For giving your chains and agents access to the real world.\n",
    "3.  **Agents:** For making decisions and using tools to accomplish goals.\n",
    "4.  **Memory:** For remembering past interactions.\n",
    "\n",
    "Mastering these concepts is the key to unlocking the full potential of LangChain.\n",
    "\n",
    "In the next chapter, we'll shift our focus to a higher-level framework, **CrewAI**, which is specifically designed for orchestrating multi-agent collaboration. You'll see how it builds on the foundational ideas we've covered here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
